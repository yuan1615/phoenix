
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Phoenix: To be determined </title>
      <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
      <script>
         function play(path) {{
           var player = document.getElementById('player');
           player.src = path;
           player.play();
         }}
      </script>
      <style>
         .audio-cell {
         /* Center audio widgets in the table cell. */
         text-align: center;
         padding-bottom: 1px;
         padding-top: 1px;
         }
         .audio-cell-padded {
         text-align: center;
         padding-bottom: 10px;
         padding-top: 10px;
         }
         .audio-header {
         /* Don't wrap header text. */
         white-space: nowrap;
         /* Some breaking space between headers for readability. */
         padding-right: 5px;
         padding-left: 5px;
         }
         .reference-cell {
         /* For uniformity and to wrap long reference text, limit the reference cell's width. */
         width: 25%;
         padding-top: 20px;
         padding-bottom: 20px;
         }
         .sample audio {
         vertical-align: middle;
         padding-left: 3px;
         padding-right: 3px;
         }
         .round-button {
         box-sizing: border-box;
         display:block;
         width:30px;
         height:30px;
         padding-top: 8px;
         padding-left: 3px;
         line-height: 6px;
         border: 1.2px solid #000;
         border-radius: 50%;
         color: #000;
         text-align:center;
         background-color: rgba(0,0,0,0.00);
         font-size:6px;
         box-shadow: 0px 0px 2px rgba(0,0,0,1);
         transition: all 0.2s ease;
         }
         .round-button:hover {
         background-color: rgba(0,0,0,0.0);
         box-shadow: 0px 0px 4px rgba(0,0,0,1);
         }
         .round-button:active {
         background-color: rgba(0,0,0,0.01);
         box-shadow: 0px 0px 1px rgba(0,0,0,1);
         }
      </style>
   </head>
   <body>
     <div class="main">
       <article>
         <header>
            <h1>Phoenix: To be determined</h1>
         </header>
      </article>
      <div>
        <p>
		<a href="https://yuan1615.github.io/about/"> Xin Yuan</a>,
	  	ZeZhou Xu,
		</p>
      </div>
      <div>
      <p><b>Abstract: </b>
Phoenix: To be determined
	  <br /><br />
      <img src="data/phoenix.png" width="300px" class="center"/> <br />
      </p>


<!-- 
<hr>
<h2 id="intermediate">Comparison on a synthesized dataset:</h2>
<p>
This section shows samples of the objective experiments. We evaluated the effectiveness of w2v-BERT [1] and PnG-BERT [2] while comparing the sound quality between the studio-recorded original speech and restored samples from artificially contaminated samples.
Each table includes the studio-recorded clean target, simulated noisy signal, and outputs of four patterns model using either w2v-BERT features or log-mel spectrogram as the input feature. The four pattern include "full model (i.e. uses both PnG-BERT features and speaker embedding [3])", "w/o text conditioning (i.e. without PnG-BERT)", "w/o speaker embedding", and "w/o text conditioning & speaker embedding".
</p>

<p>

<table>
<tbody>
    <b>Example 1: </b> <I>The Albanian Minister sidestepped the Italian Military Mission, and appointed himself Chief of Staff.</I> <br />
    <tr>
        <th align="center"> </th>
        <th align="center"> Clean target<br /></th>
        <th align="center"> Noisy input<br /></th>
    </tr>
    <tr>
        <th align="center"> </th>
        <td align="center"> <audio controls=""><source src="data/obj1_clean.wav"></audio> <img src="data/obj1_gt.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj1_noisy.wav"></audio> <img src="data/obj1_noisy.png" width="300" alt=""/></td>
    </tr>
    <tr>
        <th align="center"> <br /></th>
    </tr>
    <tr>
        <th align="center"> Feature<br /></th>
        <th align="center"> Full model<br /></th>
        <th align="center"> w/o text conditioning<br /></th>
        <th align="center"> w/o speaker embedding<br /></th>
        <th align="center"> w/o text conditioning & speaker embedding<br /></th>
    </tr>
    <tr>
        <th align="center">w2v-BERT</th>
        <td align="center"> <audio controls=""><source src="data/obj1_w2v.wav"></audio> <img src="data/obj1_w2v_full.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj1_w2v_wo_text.wav"></audio> <img src="data/obj1_w2v_wo_png.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj1_w2v_wo_dvec.wav"></audio> <img src="data/obj1_w2v_wo_dvec.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj1_w2v_wo_text_dvec.wav"></audio> <img src="data/obj1_w2v_wo_png_dvec.png" width="300" alt=""/></td>
    </tr>
    <tr>
        <th align="center">log-mel</th>
        <td align="center"> <audio controls=""><source src="data/obj1_logmel.wav"></audio> <img src="data/obj1_logmel_full.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj1_logmel_wo_text.wav"></audio> <img src="data/obj1_logmel_wo_png.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj1_logmel_wo_dvec.wav"></audio> <img src="data/obj1_logmel_wo_dvec.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj1_logmel_wo_text_dvec.wav"></audio> <img src="data/obj1_logmel_wo_png_dvec.png" width="300" alt=""/></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example 2: </b> <I>Thanks again for sharing your story so others can get help sooner than I did.</I> <br />
    <tr>
        <th align="center"> </th>
        <th align="center"> Clean target<br /></th>
        <th align="center"> Noisy input<br /></th>
    </tr>
    <tr>
        <th align="center"> </th>
        <td align="center"> <audio controls=""><source src="data/obj0_clean.wav"></audio> <img src="data/obj0_gt.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj0_noisy.wav"></audio> <img src="data/obj0_noisy.png" width="300" alt=""/></td>
    </tr>
    <tr>
        <th align="center"> <br /></th>
    </tr>
    <tr>
        <th align="center"> Feature<br /></th>
        <th align="center"> Full model<br /></th>
        <th align="center"> w/o text conditioning<br /></th>
        <th align="center"> w/o speaker embedding<br /></th>
        <th align="center"> w/o text conditioning & speaker embedding<br /></th>
    </tr>
    <tr>
        <th align="center">w2v-BERT</th>
        <td align="center"> <audio controls=""><source src="data/obj0_w2v.wav"></audio> <img src="data/obj0_w2v_full.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj0_w2v_wo_text.wav"></audio> <img src="data/obj0_w2v_wo_png.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj0_w2v_wo_dvec.wav"></audio> <img src="data/obj0_w2v_wo_dvec.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj0_w2v_wo_text_dvec.wav"></audio> <img src="data/obj0_w2v_wo_png_dvec.png" width="300" alt=""/></td>
    </tr>
    <tr>
        <th align="center">log-mel</th>
        <td align="center"> <audio controls=""><source src="data/obj0_logmel.wav"></audio> <img src="data/obj0_logmel_full.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj0_logmel_wo_text.wav"></audio> <img src="data/obj0_logmel_wo_png.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj0_logmel_wo_dvec.wav"></audio> <img src="data/obj0_logmel_wo_dvec.png" width="300" alt=""/></td>
        <td align="center"> <audio controls=""><source src="data/obj0_logmel_wo_text_dvec.wav"></audio> <img src="data/obj0_logmel_wo_png_dvec.png" width="300" alt=""/></td>
    </tr>
</tbody>
</table><br /><br />
</p>


<hr>
<h2 id="intermediate">Importance of text-conditioning (force-alignment results):</h2> 

<p>
To demonstrate the effects of text-conditioning in more detail, we performed force-alignment using a LSTM-based ASR model between the restored speech and the ground-truth text. The following examples show that if the input is severely distorted, even using w2v-BERT features, some words cannot be restored, resulting in less accurate force-alignment. Alignment of phonemes and waveforms is especially important for training the acoustic model in a TTS system. Therefore, text-conditioning is very important in Miipher purpose (and perhaps also in robust speech restoration).
</p>


<p>

<table>
<tbody>
    <b>Transcript: </b> <I>Attempting to appease dictatorial regimes with custom beanie babies is a tried and true strategy.</I> <br />
    <tr>
        <th align="center"> </th>
        <th align="center"> 
			Clean target<br />
			<audio controls=""><source src="data/force_align/force_align_ex1_clean.wav"></audio> <br />
			<img src="data/force_align/force_align_ex1_clean.png" width="1200" alt=""/>
		</th>
    </tr>
    <tr>
        <th align="center"> </th>
        <th align="center"> 
			Noisy input<br />
			<audio controls=""><source src="data/force_align/force_align_ex1_noisy.wav"></audio> <br />
			<img src="data/force_align/force_align_ex1_noisy.png" width="1200" alt=""/>
		</th>
    </tr>
    <tr>
        <th align="center"> </th>
        <th align="center"> 
			Miipher output: w2v-BERT <font color="red">with</font> text-conditioning<br />
			<audio controls=""><source src="data/force_align/force_align_ex1_w2vb_full.wav"></audio> <br />
			<img src="data/force_align/force_align_ex1_w2vb_full.png" width="1200" alt=""/>
		</th>
    </tr>
    <tr>
        <th align="center"> </th>
        <th align="center"> 
			Miipher output: w2v-BERT <font color="red">without</font> text-conditioning<br />
			<audio controls=""><source src="data/force_align/force_align_ex1_w2vb_wo_text.wav"></audio> <br />
			<img src="data/force_align/force_align_ex1_w2vb_wo_text.png" width="1200" alt=""/>
		</th>
    </tr>
</tbody>
</table><br />

</p>



<hr>
<h2 id="intermediate">Common Voice restoration & TTS outputs:</h2> 

<p>
We applied our SR model to the Common Voice dataset [4] which is an automatic speech recognition (ASR) dataset collected by a crowdsourcing project. We show that our SR model can restore speech samples in-the-wild that contain various types of speech degradation, and enable us to train a TTS model from the restored speech samples.<br><br>

The first block shows the ground-truth samples of the original Common Voice and restored Common Voice.
The second block shows the generated speech of a TTS model trained on the restored Common Voice.
The TTS model consists of a duration unsupervised non-attentive Tacotron (NAT) [5] acoustic model and a WaveRNN neural vocoder [6]. Note that we did not use speaker ID because Common Voice is prohibited from identifying the speaker. That is, it was trained as a single-speaker TTS model.
</p>

<p>
<h3 id="intermediate">Ground-truth example restoration:</h3>
<table>
<tbody>
    <b>Example1: </b> <I>ACCESS MY VIMEO SERVICE TO PLAY MUSIC FROM BERNHARD FLEISCHMANN.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv2.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/cv2_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example2: </b> <I>CHERYL ASKED ME ABOUT VISITING THE POETRY SLAM WITH HER TOMORROW.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv1.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/cv1_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example3: </b> <I>THEIR FACES WERE HIDDEN BEHIND BLUE VEILS, WITH ONLY THEIR EYES SHOWING.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv3.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/cv3_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example4: </b> <I>I AM GLAD WE HAVE DECIDED THIS THEN.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv4.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/cv4_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />
</p>



<p>
<h3 id="intermediate">TTS using LJspeech sentences:</h3>

<table>
<tbody>
    <b>Example 1: </b> <I>He seems to have felt no responsibility as to the welfare or comfort of those in charge, and out of whom he made all his money.</I> <br />
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv1_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example 2: </b> <I>Prisoners who could afford it sometimes paid for four beds, at the rate of twenty-eight shillings, and so secured the luxury of a private room.</I> <br />
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv2_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example 3: </b> <I>and to pay overseers or instructors out of the county rates.</I> <br />
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv3_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example 4: </b> <I>but no steps were taken to prevent any prisoner from obtaining more if he could pay for it.</I> <br />
    <tr>
        <td align="center"> <audio controls=""><source src="data/cv4_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />
</p>




<hr>
<h2 id="intermediate">LibriVox restoration & TTS outputs:</h2> 

<p>
As well as the above Common Voice examples, we applied our SR model to speech samples from LibriVox [7]. The restored training dataset contains 13,270 hours of speech samples spoken by 4,000 speakers.
We show that our SR model enables us to train a multi-speaker TTS model from the restored speech samples collected from the web.<br><br>

The first block shows the ground-truth samples of the original LibriVox and restored LibriVox. The second block shows the generated speech of the multi-speaker TTS model. The TTS model and all hyper-parameters were the same as the above Common Voice TTS model except for the number of class for the speaker ID embedding layer.
</p>

<p>
<h3 id="intermediate">Ground-truth example restoration:</h3>

<table>
<tbody>
    <b>Example1: </b> <I>And he, vain and blustering as usual, gave out that he was ready to prove his innocence in person against whomsoever would dare to maintain that he was guilty.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox1.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox1_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example2: </b> <I>His end--for it cannot correctly be called his death--was singular and mysterious.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox4.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox4_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example3: </b> <I>And the Evidence whereon they were Convicted, stood upon divers particular Circumstances.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox2.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox2_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example4: </b> <I>He also painted a round picture of Our Lady, which is in the Audience Chamber of the Captains of the Guelph party--a very beautiful work.</I> <br />
    <tr>
        <td align="center"> Original</td>
        <td align="center"> Restored</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox3.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox3_r.wav"></audio></td>
    </tr>
</tbody>
</table><br />
</p>


<p>
<h3 id="intermediate">TTS using LJspeech sentences:</h3>


<table>
<tbody>
    <b>Example 1: </b> <I>He seems to have felt no responsibility as to the welfare or comfort of those in charge, and out of whom he made all his money.</I> <br />
    <tr>        
        <td align="center"> Speaker ID : 10801</td>
        <td align="center"> Speaker ID : 4788</td>
        <td align="center"> Speaker ID : 8138</td>
        <td align="center"> Speaker ID : 5968</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox1_tts_10801.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox1_tts_4788.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox1_tts_8138.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox1_tts_5968.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example 2: </b> <I>Prisoners who could afford it sometimes paid for four beds, at the rate of twenty-eight shillings, and so secured the luxury of a private room.</I> <br />
    <tr>        
        <td align="center"> Speaker ID : 10801</td>
        <td align="center"> Speaker ID : 4788</td>
        <td align="center"> Speaker ID : 8138</td>
        <td align="center"> Speaker ID : 5968</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox2_tts_10801.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox2_tts_4788.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox2_tts_8138.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox2_tts_5968.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example 3: </b> <I>and to pay overseers or instructors out of the county rates.</I> <br />
    <tr>        
        <td align="center"> Speaker ID : 10801</td>
        <td align="center"> Speaker ID : 4788</td>
        <td align="center"> Speaker ID : 8138</td>
        <td align="center"> Speaker ID : 5968</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox3_tts_10801.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox3_tts_4788.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox3_tts_8138.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox3_tts_5968.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>Example 4: </b> <I>but no steps were taken to prevent any prisoner from obtaining more if he could pay for it.</I> <br />
    <tr>        
        <td align="center"> Speaker ID : 10801</td>
        <td align="center"> Speaker ID : 4788</td>
        <td align="center"> Speaker ID : 8138</td>
        <td align="center"> Speaker ID : 5968</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/vox4_tts_10801.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox4_tts_4788.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox4_tts_8138.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/vox4_tts_5968.wav"></audio></td>
    </tr>
</tbody>
</table><br />
</p>
</p>




<hr>
<h2 id="intermediate">LJspeech restoration & TTS outputs:</h2>

<p>
We applied our SR model to the LJspeech corpus [8] which has been used as a standard TTS dataset. We show that by only changing the training dataset to the restored LJspeech (called LJspeech-R), the quality of TTS outputs improves without changing the model or hyper-parameters.<br><br>

The first two column shows the ground-truth samples of the original LJspeech and LJspeech-R (our SR model outputs).
And the later two columns show the generated speech of TTS models trained on either LJspeech or LJspeech-R.
The TTS model and all hyper-parameters were the same as the above Common Voice TTS model.
</p>

<p>
<table>
<tbody>
    <b>LJ002-0201.wav: </b> <I>He seems to have felt no responsibility as to the welfare or comfort of those in charge, and out of whom he made all his money.</I> <br />
    <tr>
        <td align="center"> LJspeech ground-truth</td>
        <td align="center"> LJspeech-R ground-truth</td>
        <td align="center"> TTS trained on LJSpeech</td>
        <td align="center"> TTS trained on LJSpeech-R</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/lj1_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj1_r_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj1_tts.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj1_r_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>LJ003-0169.wav: </b> <I>Prisoners who could afford it sometimes paid for four beds, at the rate of twenty-eight shillings, and so secured the luxury of a private room.</I> <br />
    <tr>
        <td align="center"> LJspeech ground-truth</td>
        <td align="center"> LJspeech-R ground-truth</td>
        <td align="center"> TTS trained on LJSpeech</td>
        <td align="center"> TTS trained on LJSpeech-R</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/lj2_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj2_r_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj2_tts.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj2_r_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>LJ004-0089.wav: </b> <I>and to pay overseers or instructors out of the county rates.</I> <br />
    <tr>
        <td align="center"> LJspeech ground-truth</td>
        <td align="center"> LJspeech-R ground-truth</td>
        <td align="center"> TTS trained on LJSpeech</td>
        <td align="center"> TTS trained on LJSpeech-R</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/lj3_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj3_r_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj3_tts.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj3_r_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />

<table>
<tbody>
    <b>LJ006-0214.wav: </b> <I>but no steps were taken to prevent any prisoner from obtaining more if he could pay for it.</I> <br />
    <tr>
        <td align="center"> LJspeech ground-truth</td>
        <td align="center"> LJspeech-R ground-truth</td>
        <td align="center"> TTS trained on LJSpeech</td>
        <td align="center"> TTS trained on LJSpeech-R</td>
    </tr>
    <tr>
        <td align="center"> <audio controls=""><source src="data/lj4_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj4_r_gt.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj4_tts.wav"></audio></td>
        <td align="center"> <audio controls=""><source src="data/lj4_r_tts.wav"></audio></td>
    </tr>
</tbody>
</table><br />
</p>
 -->




<hr>
<h2 id="references">Acknowledgement:</h2>
<p>
Phoenix: To be determined
</p>





<h2 id="references">References:</h2>
<p>
[1] Xin Yuan, Robin Feng, Mingming Ye, Cheng Tuo, Minhang Zhang
"AdaVocoder: Adaptive Vocoder for Custom Voice,"
In Proc. INTERSPEECH, 2022.
[<a href="https://www.isca-speech.org/archive/interspeech_2022/yuan22_interspeech.html">paper</a>]<br/>

</p>

      </div>
   </body>
</html>
